{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyPwyO4S1c/av5qygRUVjAr+",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/samartha007/Psoriasis-detection-using-transfer-learning/blob/New-random-sampling-method/Alternative_sampling_approach_Mobile_net_parameter_tuweking.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, Flatten,Dropout\n",
        "from tensorflow.keras.optimizers import Adam, SGD\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix,roc_curve,auc\n",
        "\n",
        "\n",
        "from keras.applications.mobilenet import MobileNet\n",
        "import os\n",
        "import numpy as np\n",
        "from PIL import Image\n",
        "import matplotlib.pyplot as plt\n",
        "#### Modeling\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from keras import Sequential\n",
        "from keras.layers import Dense,Conv2D,MaxPooling2D,Flatten,BatchNormalization,Dropout\n",
        "from tensorflow.keras.optimizers import Adam,SGD\n",
        "from sklearn.model_selection import train_test_split\n",
        "from tensorflow.keras.applications.vgg16 import preprocess_input\n",
        "from tensorflow.keras.applications import VGG16\n",
        "from tensorflow.keras.applications.inception_v3 import InceptionV3\n",
        "from tensorflow.keras.applications.xception import Xception\n",
        "from tensorflow.keras.applications import EfficientNetB0\n",
        "from keras.applications.mobilenet import MobileNet\n",
        "from keras.applications.vgg19 import VGG19\n",
        "from tensorflow.keras.applications import ResNet50\n",
        "from sklearn.model_selection import cross_val_score,cross_val_predict, StratifiedKFold\n",
        "from tensorflow.keras.wrappers.scikit_learn import KerasClassifier\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix\n",
        "from sklearn import metrics\n",
        "from sklearn.metrics import roc_curve, auc\n",
        "\n"
      ],
      "metadata": {
        "id": "ed8E_85cBe5G"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "\n",
        "drive.mount('/content/gdrive/', force_remount=True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "btKCsVHsRss2",
        "outputId": "baae6013-a0bf-4553-fabf-ae9969a1d718"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/gdrive/\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "lOq51KsiQt2L"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import numpy as np\n",
        "from PIL import Image\n",
        "from sklearn.model_selection import train_test_split\n",
        "from tensorflow.keras.applications.vgg16 import preprocess_input\n",
        "\n",
        "# Path to the directories containing the class data\n",
        "class_1_directory = '/content/gdrive/MyDrive/all patch data/all patch data/disease_with_online_data'\n",
        "class_2_directory = '/content/gdrive/MyDrive/all patch data/all patch data/normal'\n",
        "\n",
        "# Get a list of image filenames for each class\n",
        "class_1_filenames = os.listdir(class_1_directory)\n",
        "class_2_filenames = os.listdir(class_2_directory)\n",
        "\n",
        "# Create empty lists to store the data and labels\n",
        "data = []\n",
        "labels = []\n",
        "\n",
        "# Loop over each image in class 1\n",
        "for image_filename in class_1_filenames:\n",
        "    # Read the image\n",
        "    image_path = os.path.join(class_1_directory, image_filename)\n",
        "    image = Image.open(image_path)\n",
        "\n",
        "    # Preprocess the image for VGG16\n",
        "    image = image.resize((224, 224))\n",
        "    # image = image.convert('RGB')\n",
        "    image = np.array(image)\n",
        "    # image = preprocess_input(image)\n",
        "\n",
        "    # Add the preprocessed image and corresponding label to the lists\n",
        "    data.append(image)\n",
        "    labels.append(0)  # Class 1 is labeled as 0\n",
        "\n",
        "# Loop over each image in class 2\n",
        "for image_filename in class_2_filenames:\n",
        "    # Read the image\n",
        "    image_path = os.path.join(class_2_directory, image_filename)\n",
        "    image = Image.open(image_path)\n",
        "\n",
        "    # Preprocess the image for VGG16\n",
        "    image = image.resize((224, 224))\n",
        "    # image = image.convert('RGB')\n",
        "    image = np.array(image)\n",
        "    # image = preprocess_input(image)\n",
        "\n",
        "    # Add the preprocessed image and corresponding label to the lists\n",
        "    data.append(image)\n",
        "    labels.append(1)  # Class 2 is labeled as 1\n",
        "\n",
        "# Convert the lists to NumPy arrays\n",
        "data = np.array(data)\n",
        "labels = np.array(labels)\n",
        "# # Normalize the image data\n",
        "data = data / 255.0\n",
        "# Split the data into training and testing sets\n",
        "X_train1, X_test1, y_train1, y_test1 = train_test_split(data, labels, test_size=0.2, random_state=42)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## For Mobile Net application using the Newly mentioned method"
      ],
      "metadata": {
        "id": "WE8iGPnRL6E5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#### SIR Newly Mentioned Logic of sampling\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import roc_auc_score, roc_curve, confusion_matrix\n",
        "sns=[]\n",
        "spc=[]\n",
        "AUC=[]\n",
        "validation_loss=[]\n",
        "validation_accuracy=[]\n",
        "# Assuming you have your feature data in 'X' and labels in 'y'\n",
        "# Define your model as 'model'\n",
        "# Define the number of epochs as 'num_epochs'\n",
        "def sir_method(base,height,width):\n",
        "# Get the total number of samples\n",
        "  num_samples = len(labels)\n",
        "  num_epochs=10\n",
        "  train_ratio = 0.8\n",
        "  # Convert train_ratio to an absolute number of samples\n",
        "  train_size = int(train_ratio * len(data))\n",
        "  for epoch in range(num_epochs):\n",
        "# Randomly split the data into training and validation sets for this epoch\n",
        "      X_train, X_val, y_train, y_val = train_test_split(data, labels, train_size=train_size, random_state=epoch)\n",
        "      base_model = base(weights='imagenet', include_top=False, input_shape=(height, width, 3))\n",
        "\n",
        "        # Set up the model architecture\n",
        "      model = Sequential()\n",
        "      model.add(base_model)\n",
        "      model.add(Flatten())\n",
        "      model.add(Dense(height, activation='relu'))\n",
        "      model.add(Dropout(0.5))\n",
        "      model.add(Dense(1, activation='sigmoid'))\n",
        "      base_model.trainable = False\n",
        "\n",
        "      # Compile the model\n",
        "      model.compile(optimizer=Adam(learning_rate=0.001), loss='binary_crossentropy', metrics=['accuracy'])\n",
        "      # Train the model on the training set\n",
        "      model.fit(X_train, y_train, epochs=1, batch_size=50, verbose=0)\n",
        "      # Evaluate the model on the validation set\n",
        "      val_loss, val_acc = model.evaluate(X_val, y_val, verbose=0)\n",
        "      validation_loss.append(val_loss)\n",
        "      validation_accuracy.append(val_acc)\n",
        "      # Make predictions on the validation set\n",
        "      y_pred = model.predict(X_val)\n",
        "\n",
        "      # Calculate sensitivity, specificity, and AUC\n",
        "      cm = confusion_matrix(y_val, np.round(y_pred))\n",
        "      tn, fp, fn, tp = cm.ravel()\n",
        "      sensitivity = tp / (tp + fn)\n",
        "      specificity = tn / (tn + fp)\n",
        "      auc = roc_auc_score(y_val, y_pred)\n",
        "      sns.append(sensitivity)\n",
        "      spc.append(specificity)\n",
        "      AUC.append(auc)\n",
        "\n",
        "      # Print the evaluation metrics\n",
        "      # print(f\"Epoch {epoch+1} - Sensitivity: {sensitivity:.4f} - Specificity: {specificity:.4f} - AUC: {auc:.4f}\")\n",
        "  return sns,spc,AUC,validation_loss,validation_accuracy\n"
      ],
      "metadata": {
        "id": "HIVIYkM0r6JD"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "mobile_net_sns,mobile_net_spc,mobile_net_auc,mobile_net_val_loss,mobile_net_val_acc=sir_method(MobileNet,224,224)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HY1L525muWKU",
        "outputId": "18207567-1b3a-4d63-af7c-2f2fe3888af5"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/mobilenet/mobilenet_1_0_224_tf_no_top.h5\n",
            "17225924/17225924 [==============================] - 0s 0us/step\n",
            "3/3 [==============================] - 1s 30ms/step\n",
            "3/3 [==============================] - 0s 30ms/step\n",
            "3/3 [==============================] - 1s 30ms/step\n",
            "3/3 [==============================] - 1s 30ms/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_test_function.<locals>.test_function at 0x79e613c03250> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
            "WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_predict_function.<locals>.predict_function at 0x79e5dc0a6290> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "3/3 [==============================] - 1s 32ms/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_test_function.<locals>.test_function at 0x79e6171bc3a0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
            "WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_predict_function.<locals>.predict_function at 0x79e6171bf910> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "3/3 [==============================] - 1s 33ms/step\n",
            "3/3 [==============================] - 1s 38ms/step\n",
            "3/3 [==============================] - 1s 38ms/step\n",
            "3/3 [==============================] - 0s 30ms/step\n",
            "3/3 [==============================] - 1s 41ms/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(f'Mean sensitivity of MobileNet after 10 epochs {np.mean(mobile_net_sns)}')\n",
        "print(f'Mean specificity after 10 epochs {np.mean(mobile_net_spc)}')\n",
        "print(f'Mean AUC after 10 epochs {np.mean(mobile_net_auc)}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2K2pCs9T8Jj1",
        "outputId": "3df8dc32-60de-443f-faa2-7e23e2a178f7"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mean sensitivity of MobileNet after 10 epochs 0.9285981986949728\n",
            "Mean specificity after 10 epochs 0.9085221691682797\n",
            "Mean AUC after 10 epochs 0.9845283197541465\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### For Resnet-50 application"
      ],
      "metadata": {
        "id": "eNNqcW8EKa0B"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "res_net_sns,res_net_spc,res_net_auc,res_net_val_loss,res_net_val_acc=sir_method(ResNet50,224,224)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Vze8EUMnJ3Yx",
        "outputId": "1da80f84-3374-487c-e997-6e837fb8851f"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/resnet/resnet50_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
            "94765736/94765736 [==============================] - 0s 0us/step\n",
            "3/3 [==============================] - 1s 83ms/step\n",
            "3/3 [==============================] - 1s 83ms/step\n",
            "3/3 [==============================] - 2s 87ms/step\n",
            "3/3 [==============================] - 2s 86ms/step\n",
            "3/3 [==============================] - 1s 83ms/step\n",
            "3/3 [==============================] - 1s 90ms/step\n",
            "3/3 [==============================] - 1s 85ms/step\n",
            "3/3 [==============================] - 1s 86ms/step\n",
            "3/3 [==============================] - 1s 85ms/step\n",
            "3/3 [==============================] - 1s 83ms/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(f'Mean sensitivity of VGG16 after 10 epochs {np.mean(res_net_sns)}')\n",
        "print(f'Mean specificity of VGG16 after 10 epochs {np.mean(res_net_spc)}')\n",
        "print(f'Mean AUC of VGG16 after 10 epochs {np.mean(res_net_auc)}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3wRKV60cMIaU",
        "outputId": "a7a76a18-340f-48e8-bd6e-a32d16e236fe"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mean sensitivity of VGG16 after 10 epochs 0.6142990993474864\n",
            "Mean specificity of VGG16 after 10 epochs 0.8066185407244909\n",
            "Mean AUC of VGG16 after 10 epochs 0.9479971040787876\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## For VGG 16 and 19 application"
      ],
      "metadata": {
        "id": "0XnEiTtZLnUm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "vgg16_sns,vgg16_spc,vgg16_auc,vgg16_val_loss,vgg16_val_acc=sir_method(VGG16,224,224)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RAref58t63At",
        "outputId": "efa98ca9-5f50-4a5c-ba2f-0ef86eb8507a"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/vgg16/vgg16_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
            "58889256/58889256 [==============================] - 0s 0us/step\n",
            "3/3 [==============================] - 0s 149ms/step\n",
            "3/3 [==============================] - 0s 115ms/step\n",
            "3/3 [==============================] - 0s 117ms/step\n",
            "3/3 [==============================] - 0s 119ms/step\n",
            "3/3 [==============================] - 0s 120ms/step\n",
            "3/3 [==============================] - 0s 117ms/step\n",
            "3/3 [==============================] - 0s 120ms/step\n",
            "3/3 [==============================] - 0s 118ms/step\n",
            "3/3 [==============================] - 0s 117ms/step\n",
            "3/3 [==============================] - 0s 122ms/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(f'Mean sensitivity of VGG16 after 10 epochs {np.mean(vgg16_sns)}')\n",
        "print(f'Mean specificity of VGG16 after 10 epochs {np.mean(vgg16_spc)}')\n",
        "print(f'Mean AUC of VGG16 after 10 epochs {np.mean(vgg16_auc)}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "65tUQ1RY1-6P",
        "outputId": "1112530b-fcfa-4038-9bee-675d5d69c674"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mean sensitivity of VGG16 after 10 epochs 0.6754573327906662\n",
            "Mean specificity of VGG16 after 10 epochs 0.8094126366029606\n",
            "Mean AUC of VGG16 after 10 epochs 0.936981443545062\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "vgg19_sns,vgg19_spc,vgg19_auc,vgg19_val_loss,vgg19_val_acc=sir_method(VGG19,224,224)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lwUCWY1a85qr",
        "outputId": "14811740-aa11-4067-d682-276f351210fc"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/vgg19/vgg19_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
            "80134624/80134624 [==============================] - 0s 0us/step\n",
            "3/3 [==============================] - 1s 145ms/step\n",
            "3/3 [==============================] - 0s 144ms/step\n",
            "3/3 [==============================] - 0s 145ms/step\n",
            "3/3 [==============================] - 0s 144ms/step\n",
            "3/3 [==============================] - 0s 145ms/step\n",
            "3/3 [==============================] - 0s 146ms/step\n",
            "3/3 [==============================] - 0s 147ms/step\n",
            "3/3 [==============================] - 0s 146ms/step\n",
            "3/3 [==============================] - 0s 145ms/step\n",
            "3/3 [==============================] - 1s 148ms/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(f'Mean sensitivity of VGG19 after 10 epochs {np.mean(vgg19_sns)}')\n",
        "print(f'Mean specificity of VGG19 after 10 epochs {np.mean(vgg19_spc)}')\n",
        "print(f'Mean AUC of VGG19 after 10 epochs {np.mean(vgg19_auc)}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BoqNfVDr85pf",
        "outputId": "0a3f59c1-634d-49c2-8123-d41e2d83cf9f"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mean sensitivity of VGG19 after 10 epochs 0.6563112929483897\n",
            "Mean specificity of VGG19 after 10 epochs 0.8305280346902351\n",
            "Mean AUC of VGG19 after 10 epochs 0.9377533541148553\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Fine Tuning of Mobile Net"
      ],
      "metadata": {
        "id": "bLMhcrBBLwqO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#### SIR Newly Mentioned Logic of sampling\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import roc_auc_score, roc_curve, confusion_matrix\n",
        "sns=[]\n",
        "spc=[]\n",
        "AUC=[]\n",
        "validation_loss=[]\n",
        "validation_accuracy=[]\n",
        "# Assuming you have your feature data in 'X' and labels in 'y'\n",
        "# Define your model as 'model'\n",
        "# Define the number of epochs as 'num_epochs'\n",
        "def sir_method_fine_tuned_model(base,height,width):\n",
        "# Get the total number of samples\n",
        "  num_samples = len(labels)\n",
        "  num_epochs=10\n",
        "  train_ratio = 0.8\n",
        "  # Convert train_ratio to an absolute number of samples\n",
        "  train_size = int(train_ratio * len(data))\n",
        "  for epoch in range(num_epochs):\n",
        "      # Shuffle the data and labels\n",
        "      X_train, X_val, y_train, y_val = train_test_split(data, labels, train_size=train_size, random_state=epoch)\n",
        "      base_model = base(weights='imagenet', include_top=False, input_shape=(height, width, 3))\n",
        "\n",
        "        # Set up the model architecture\n",
        "      model = Sequential()\n",
        "      model.add(base_model)\n",
        "      model.add(Flatten())\n",
        "      model.add(Dense(height, activation='relu'))\n",
        "      model.add(Dropout(0.5))\n",
        "      model.add(Dense(1, activation='sigmoid'))\n",
        "      base_model.trainable = False\n",
        "\n",
        "      # Compile the model\n",
        "      model.compile(optimizer=Adam(learning_rate=0.0001), loss='binary_crossentropy', metrics=['accuracy'])\n",
        "      # Train the model on the training set\n",
        "      model.fit(X_train, y_train, epochs=1, batch_size=50, verbose=0)\n",
        "      # Evaluate the model on the validation set\n",
        "      val_loss, val_acc = model.evaluate(X_val, y_val, verbose=0)\n",
        "      validation_loss.append(val_loss)\n",
        "      validation_accuracy.append(val_acc)\n",
        "      # Make predictions on the validation set\n",
        "      y_pred = model.predict(X_val)\n",
        "\n",
        "      # Calculate sensitivity, specificity, and AUC\n",
        "      cm = confusion_matrix(y_val, np.round(y_pred))\n",
        "      tn, fp, fn, tp = cm.ravel()\n",
        "      sensitivity = tp / (tp + fn)\n",
        "      specificity = tn / (tn + fp)\n",
        "      auc = roc_auc_score(y_val, y_pred)\n",
        "      sns.append(sensitivity)\n",
        "      spc.append(specificity)\n",
        "      AUC.append(auc)\n",
        "\n",
        "      # Print the evaluation metrics\n",
        "      # print(f\"Epoch {epoch+1} - Sensitivity: {sensitivity:.4f} - Specificity: {specificity:.4f} - AUC: {auc:.4f}\")\n",
        "  return sns,spc,AUC,validation_loss,validation_accuracy\n"
      ],
      "metadata": {
        "id": "6T-lmkGL9a6X"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "fine_tuned_sns,fine_tuned_spc,fine_tuned_auc,fine_tuned_val_loss,fine_tuned_val_acc=sir_method_fine_tuned_model(MobileNet,224,224)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LoM8XXDe9qKv",
        "outputId": "8fb036e8-896f-4a2d-94e5-a28c0c49d064"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "3/3 [==============================] - 1s 32ms/step\n",
            "3/3 [==============================] - 1s 40ms/step\n",
            "3/3 [==============================] - 1s 31ms/step\n",
            "3/3 [==============================] - 1s 31ms/step\n",
            "3/3 [==============================] - 0s 31ms/step\n",
            "3/3 [==============================] - 1s 29ms/step\n",
            "3/3 [==============================] - 1s 31ms/step\n",
            "3/3 [==============================] - 0s 30ms/step\n",
            "3/3 [==============================] - 0s 30ms/step\n",
            "3/3 [==============================] - 1s 31ms/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(f'Mean sensitivity of fine tuned MobileNet after 10 epochs {np.mean(fine_tuned_sns)}')\n",
        "print(f'Standard deviation sensitivity of fine tuned MobileNet after 10 epochs {np.var(fine_tuned_sns)}')\n",
        "print(f'Mean specificity of fine tuned MobileNet after 10 epochs {np.mean(fine_tuned_spc)}')\n",
        "print(f'Standard deviation specificity of fine tuned MobileNet after 10 epochs {np.var(fine_tuned_spc)}')\n",
        "print(f'Mean AUC of fine tuned MobileNet after 10 epochs {np.mean(fine_tuned_auc)}')\n",
        "print(f'Standard deviation AUC of fine tuned MobileNet after 10 epochs {np.var(fine_tuned_auc)}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tGwZl2AU98dU",
        "outputId": "20d696e8-38fe-4e82-f82b-4690c5182329"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mean sensitivity of fine tuned MobileNet after 10 epochs 0.9602826027019576\n",
            "Standard deviation sensitivity of fine tuned MobileNet after 10 epochs 0.0025535391728199693\n",
            "Mean specificity of fine tuned MobileNet after 10 epochs 0.9136180637818516\n",
            "Standard deviation specificity of fine tuned MobileNet after 10 epochs 0.001818929924961303\n",
            "Mean AUC of fine tuned MobileNet after 10 epochs 0.9883012239606719\n",
            "Standard deviation AUC of fine tuned MobileNet after 10 epochs 0.00013964981141312413\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "np.mean(fine_tuned_val_acc)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pJT56RzEXtN_",
        "outputId": "566965f2-237d-4b59-85f7-68c08a635f73"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.9324324309825898"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    }
  ]
}